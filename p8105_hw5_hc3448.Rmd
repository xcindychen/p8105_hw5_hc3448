---
title: "p8105_hw5_hc3448"
author: "HsiYu Chen"
date: "2024-11-13"
output: github_document
---

```{r setup, include=FALSE}
library(dplyr)
library(purrr)
library(tidyr)
library(ggplot2)
set.seed(1)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


### Problem 1

```{r}
bday_sim  = function(n){
  bday = sample (1:365, size = n, replace = TRUE)
  duplicate = length(unique(bday)) <n
  return(duplicate)
}
```

```{r}
sim_res = 
  expand_grid(
    n = 2:50,
    iter = 1:10000
  ) |>
  mutate(res = map_lgl(n, bday_sim)) |>
  group_by(n) |>
  summarize(prob = mean(res))
```

```{r}
sim_res |>
  ggplot(aes(x=n, y=prob)) +
  geom_line() +
  labs(
    x = "Group Size",           
    y = "Probability",        
    title = "Probability of shared birthday by group size" 
  )
  
```
  
When the group size increases, the probability that at least two people in the group will share a birthday also increases. When there's around 25 people in the group, there is higher than 50% of the probability that there are at least two people sharing a birthday. 

### Problem 2

```{r}
n = 30
sigma = 5
mu_list = 0:6
alpha = 0.05
n_dataset = 5000
```

```{r}
sim_t_test = function(mu){
  x = rnorm(n, mean = mu, sd = sigma)
  test_result = broom::tidy(t.test(x, mu = 0))
  tibble(
    estimate = test_result[["estimate"]],
    p_value = test_result[["p.value"]]
  )
}

sim_result = 
  expand_grid(
    mu = mu_list,
    iteration = 1: n_dataset
  ) |>
  mutate(
    result_df = map(mu, sim_t_test)
  ) |>
  unnest(result_df)

power_result = 
  sim_result |>
  group_by(mu) |>
  summarize(power = mean(p_value < alpha))

```

```{r}
power_result |>
  ggplot(aes(x = mu, y = power)) +
  geom_line() +
  labs(
    x = "True mean",           
    y = "Power",        
    title = "Power of one sample t-test by true mean" 
  ) 
```

The graph shows that the power of the test increases when the true means increases. It suggests that a higher the probability of rejecting the null hypothesis when the effect size is larger. 


```{r}
estimate_result =
  sim_result |>
  group_by(mu) |>
  summarize(
    avg_estimate = mean(estimate),
    avg_estimate_rej = mean(estimate[p_value < alpha], na.rm = TRUE)
  )
```


```{r}
estimate_result |>
  ggplot(aes(x = mu)) +
  geom_line(aes(y = avg_estimate, color = "All")) +
  geom_line(aes(y = avg_estimate_rej, color = "Null Rejected")) +
  labs(
    x = "True mean",           
    y = "Average estimate of mean",        
    title = "Average estimate mean by true mean (Comparing all to null rejected)" 
  )
```

The graph shows that the average estimate of μ for rejected tests is generally higher than the true value, particularly for smaller effect sizes. This inflation occurs because only larger estimates are likely to exceed the significance threshold of α = 0.05, thus skewing the average upward in cases where the null hypothesis is rejected

### Problem 3

```{r message = FALSE}
homicide_df = read.csv("data/homicide-data.csv")
```

The raw data contains `r nrow(homicide_df)` criminal homicides in 50 large U.S. cities and the variables includes the reported date, disposition, city, victims' name, sex, race, and age.

```{r}
homicide_sum = 
  homicide_df |>
  mutate(city_state = paste(city, state, sep = ", ")) |>
  group_by(city_state) |>
  summarize(
    total_number_homicides = n(),
    number_unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"),
                                    na.rm = TRUE)
  ) 
homicide_sum |> knitr::kable()
```


```{r}
baltimore_df = 
  homicide_sum |>
  filter(city_state == "Baltimore, MD")
  
baltimore_test = 
  prop.test(
    baltimore_df[['number_unsolved_homicides']],
    baltimore_df[['total_number_homicides']]
  ) |> 
  broom::tidy()

baltimore_result <- baltimore_test |> 
  select(estimate, conf.low, conf.high)

baltimore_result |> knitr::kable()
```

```{r message= FALSE, warning=FALSE }
unsolved_func = function(unsolved, total){
  test_result = prop.test(unsolved, total)
  broom::tidy(test_result) |>
    select(estimate, conf.low, conf.high)
}

all_city_unsolved =
  homicide_sum |>
  mutate(
    test_result = purrr::map2(number_unsolved_homicides, total_number_homicides, \(x,y) unsolved_func(x,y))
  )|>
  unnest(test_result)

all_city_unsolved |> knitr::kable(digit = 3)
```

```{r fig.width=10, fig.height=6}
all_city_unsolved |>
  ggplot(aes(y = reorder(city_state, estimate), x = estimate)) +
  geom_point(size = 0.5) +
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) +
  labs(
    x = "Estimated proportion of unsolved homicide",
    y = "City, State",
    title = "The estimates and CIs for each city"
  ) 
  
```

